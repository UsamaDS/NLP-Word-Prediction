{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# Predicting the next word\n",
        "\n",
        "In this work Shakespeare's sonnets has been used to create a corpus. Deep learning model has been trained on this corpus that predict the next word.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Importing Libraries \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTxqlHqKHzhr"
      },
      "source": [
        "For this work [Shakespeare Sonnets Dataset](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), which contains more than 2000 lines of text extracted from Shakespeare's sonnets has been used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ4qOUzujMP6",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dafa07-1f40-45a0-cc11-79a786ff11be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 40.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfd-nYKij5yY",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a29378-fb94-4898-93bd-6a29dc5f836b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAhM_qAZk0o5",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77-0sA46OETa"
      },
      "source": [
        "Next convert the text into sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqhPxdeXlfjh",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd897e7f-9f6c-417c-c7c7-67ac8a33e71d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmgo-vXhk4nd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b74056-3d99-48c0-edf5-bb4ea4f411be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DU7wK-eQ5dc"
      },
      "source": [
        "Notice that you received the sequence wrapped inside a list so in order to get only the desired sequence you need to explicitly get the first item in the list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpTy8WmIQ57P",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n",
        "\n",
        "Now `n_gram_seqs` function is created. This function receives the fitted tokenizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy4baJMDl6kj",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "    \n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "    \n",
        "    for line in corpus:\n",
        "      # Tokenize the current list\n",
        "      tokenList = tokenizer.texts_to_sequences([line])[0]\n",
        "    \n",
        "      for i in range(1, len(tokenList)):\n",
        "        nGramSequence = tokenList[:i+1]\n",
        "        input_sequences.append(nGramSequence) \n",
        "\n",
        "    return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlKqW2pfM7G3",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4b034e-8476-432a-f199-d483888e7571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Test function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtPpCcBjNc4c",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb0bda7-f69c-476e-b7fb-1db241f08791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Test your function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laMwiRUpmuSd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe631101-5050-4307-c438-ec70fe8462dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ],
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OciMdmEdE9L"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_grams of input_sequences have length: 15462\n",
        "maximum length of sequences is: 11\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "Now the `pad_seqs` function which will pad any given sequences to the desired maximum length. Notice that this function receives a list of sequences and should return a numpy array with the padded sequences: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "code",
        "id": "WW1-qAZaWOhC",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "    padded_sequences = np.array(pad_sequences(input_sequences, maxlen = maxlen, padding='pre'))\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqVQ0pb3YHLr",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eecdfcb-9982-44fe-ad34-08570cbeb302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213],\n",
              "       [417, 877, 166, 213, 517]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j56_UCOBYzZt",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a0d892-041b-4c6f-963d-d94f564d892e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgK-Q_micEYA",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d80787-399d-4c19-ed0e-a929f68233a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network we should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word.\n",
        "\n",
        "This function also receives the total of words in the corpus, this parameter will be very important when one hot enconding the labels since every word in the corpus will be a label at least once. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "9WGGbYdnZdmJ",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "    \n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "    \"\"\"\n",
        "    features = input_sequences[:, :-1]\n",
        "    labels = input_sequences[:, -1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes = total_words)\n",
        "\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23DolaBRaIAZ",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53320d5a-7478-4b11-a37d-a0a12b522442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,  34],\n",
              "       [  0,   0,  34, 417],\n",
              "       [  0,  34, 417, 877],\n",
              "       [ 34, 417, 877, 166],\n",
              "       [417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Test your function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRTuLEt3bRKa",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74696d0-fc21-4828-a74f-865ccebecafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "In order to predict next word Deep learning architecture has been designed by using Bidirectional LSTM with some Dense layers.\n",
        "The starting Embedding Layer will accepth  the padded sequence "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "XrE6kpJFfvRY",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "|# create_model\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "    \n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "    \n",
        "    Returns:\n",
        "        model (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1, name = \"Embedding\"))\n",
        "    model.add(Bidirectional(LSTM(64, name = \"LSTM\")))\n",
        "    model.add(Dense(128, activation = 'relu', name = \"Dense_1\"))\n",
        "    model.add(Dense(total_words, activation = 'softmax', name = \"Output\"))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IpX_Gu_gISk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d2b6dc-1797-440f-91a1-7b7b0af061be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "484/484 [==============================] - 12s 8ms/step - loss: 6.8479 - accuracy: 0.0219\n",
            "Epoch 2/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 6.4726 - accuracy: 0.0242\n",
            "Epoch 3/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 6.3168 - accuracy: 0.0323\n",
            "Epoch 4/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 6.1353 - accuracy: 0.0390\n",
            "Epoch 5/50\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 5.9394 - accuracy: 0.0444\n",
            "Epoch 6/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.7327 - accuracy: 0.0522\n",
            "Epoch 7/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 5.5059 - accuracy: 0.0673\n",
            "Epoch 8/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.2731 - accuracy: 0.0775\n",
            "Epoch 9/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.0408 - accuracy: 0.0936\n",
            "Epoch 10/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.8082 - accuracy: 0.1071\n",
            "Epoch 11/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.5791 - accuracy: 0.1241\n",
            "Epoch 12/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.3309 - accuracy: 0.1464\n",
            "Epoch 13/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.0879 - accuracy: 0.1683\n",
            "Epoch 14/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 3.8267 - accuracy: 0.2006\n",
            "Epoch 15/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 3.5723 - accuracy: 0.2346\n",
            "Epoch 16/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 3.3166 - accuracy: 0.2746\n",
            "Epoch 17/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 3.0725 - accuracy: 0.3177\n",
            "Epoch 18/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.8369 - accuracy: 0.3672\n",
            "Epoch 19/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.6219 - accuracy: 0.4124\n",
            "Epoch 20/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.4289 - accuracy: 0.4514\n",
            "Epoch 21/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.2544 - accuracy: 0.4856\n",
            "Epoch 22/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.0982 - accuracy: 0.5177\n",
            "Epoch 23/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.9669 - accuracy: 0.5512\n",
            "Epoch 24/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.8380 - accuracy: 0.5744\n",
            "Epoch 25/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.7335 - accuracy: 0.5963\n",
            "Epoch 26/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.6268 - accuracy: 0.6249\n",
            "Epoch 27/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 1.5362 - accuracy: 0.6402\n",
            "Epoch 28/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 1.4556 - accuracy: 0.6612\n",
            "Epoch 29/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.3833 - accuracy: 0.6734\n",
            "Epoch 30/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.3165 - accuracy: 0.6889\n",
            "Epoch 31/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 1.2505 - accuracy: 0.7051\n",
            "Epoch 32/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.1880 - accuracy: 0.7185\n",
            "Epoch 33/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 1.1516 - accuracy: 0.7256\n",
            "Epoch 34/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.0875 - accuracy: 0.7412\n",
            "Epoch 35/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.0493 - accuracy: 0.7475\n",
            "Epoch 36/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.0015 - accuracy: 0.7598\n",
            "Epoch 37/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.9637 - accuracy: 0.7699\n",
            "Epoch 38/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.9341 - accuracy: 0.7751\n",
            "Epoch 39/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.9271 - accuracy: 0.7748\n",
            "Epoch 40/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.8809 - accuracy: 0.7848\n",
            "Epoch 41/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.8445 - accuracy: 0.7939\n",
            "Epoch 42/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 0.8205 - accuracy: 0.7981\n",
            "Epoch 43/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7976 - accuracy: 0.8032\n",
            "Epoch 44/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7722 - accuracy: 0.8099\n",
            "Epoch 45/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7569 - accuracy: 0.8139\n",
            "Epoch 46/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 0.7489 - accuracy: 0.8144\n",
            "Epoch 47/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7552 - accuracy: 0.8107\n",
            "Epoch 48/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7124 - accuracy: 0.8189\n",
            "Epoch 49/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6897 - accuracy: 0.8270\n",
            "Epoch 50/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 0.6809 - accuracy: 0.8293\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "3b3b97f6-6f09-4390-852a-475215acc4ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3daZhU1bn28f/NFDSKYysKKJhglDjGFufoET1BTcQpvugxzsGJBMc4xQmicYzRiAMRjsZ5ViIoUYIzKo0aFZST1ohAArSKaMTI9LwfVqFl29AFXd27q+r+XVddXXvormdje7NYe+21FBGYmVnpa5N1AWZmVhwOdDOzMuFANzMrEw50M7My4UA3MysTDnQzszLhQLdWRdJjko4o9rlmlUAeh25NJenfeZsrA18Ai3Lbx0XEHS1flVnlcaBbUUl6Dzg2Ip5s4Fi7iFjY8lWVFv852Ypyl4s1G0m7SZou6UxJM4H/lbSGpEcl1Umak3vfNe97npJ0bO79kZKek3Rl7tx/SNprBc/tIekZSZ9KelLSUEm3L6XuxmpcU9L/Svpn7vjDecf6SXpN0ieS3pHUN7f/PUl75J134ZLPl9RdUkg6RtL7wF9z+++TNFPS3Fzt38/7/pUkXSVpau74c7l9oyT9ot71vC5p/+X972elx4Fuza0zsCawITCA9Dv3v7ntDYDPgeuW8f3bAVOAtYHLgeGStALn3gm8DKwFXAj8bBmf2ViNt5G6lr4PrANcDSCpN/An4AxgdeCHwHvL+Jz6dgU2BX6U234M6Jn7jFeA/K6rK4FtgB1Jf76/AhYDtwKHLTlJ0pZAF2DUctRhpSoi/PKraC9SgO2Re78bMB/ouIzztwLm5G0/ReqyATgSqM07tjIQQOflOZcUyguBlfOO3w7cXuA1fVkjsB4pONdo4LybgKsb+3PJbV+45POB7rlaN1pGDavnzlmN9BfO58CWDZzXEZgD9MxtXwlcn/XvhV8t83IL3ZpbXUT8Z8mGpJUl3ZTrKvgEeAZYXVLbpXz/zCVvImJe7u0qy3nu+sBHefsApi2t4EZq7Jb7WXMa+NZuwDtL+7kF+LImSW0lXZrrtvmEr1r6a+deHRv6rNyf9T3AYZLaAIeQ/kVhFcCBbs2t/l3304DvAdtFRCdStwTA0rpRiuFfwJqSVs7b120Z5y+rxmm5n7V6A983DfjOUn7mZ6R/NSzRuYFz8v+sDgX6AXuQWuXd82r4APjPMj7rVuB/gD7AvIgYv5TzrMw40K2lrUrqLvhY0prABc39gRExFagBLpTUQdIOwE9WpMaI+Bepb/v63M3T9pKWBP5w4ChJfSS1kdRF0ia5Y68B/XPnVwMHNVL2qqThnx+S/iK4JK+GxcAI4HeS1s+15neQ9K3c8fGkbqGrcOu8ojjQraX9HliJ1Mp8EXi8hT73f4AdSAH5G1K3xBdLObexGn8GLADeBmYDJwNExMvAUaSbpHOBp0k3VgHOI7Wo5wAXkW7SLsufgKnADGByro58pwNvABOAj4DL+Pr/z38CNifdK7AK4XHoVpEk3QO8HRHN/i+ELEg6HBgQETtnXYu1HLfQrSJI2lbSd3JdIX1J/dMPN/Z9pSh3r+BEYFjWtVjLcqBbpehMGub4b+Ba4ISIeDXTipqBpB8BdcAsGu/WsTLjLhczszLhFrqZWZlol9UHr7322tG9e/esPt7MrCRNnDjxg4ioauhYZoHevXt3ampqsvp4M7OSJGnq0o65y8XMrEw40M3MyoQD3cysTDjQzczKhAPdzKxMONDNzMqEA93MrExkNg7dzKzczZsHM2fCrFnpteT9PvtAdXXxP8+BbmZWJB9/DI8+Cg89BGPHwty5DZ+3zjoOdDOzVmfmTHjkka9CfOFCWG89+OlP4TvfgXXXhc6dv/paVQXt2zdPLQ50M7PlNHVqCvAHHoDnn4eIFN6nnAIHHAC9e0ObDO5QOtDNrKxFpH7rt95Kr8mTobY29W8vXAgLFnz96zrrQM+eX39997swY0YK8AcegCXTUG2+OZx/Phx4IGy2Gag5lzovQEGBnlvh5RqgLXBzRFxa7/gGpJXGV8+dc1ZEjC5yrWZmjZo3D557LnV/PPdcCvCPP/7q+KqrwsYbp68dO0K7dqkLpF07aNs2daGMGpX+EmjIttvCpZemlnjPni1zTYVqNNAltQWGAnsC04EJkkZGxOS8034N3BsRN0jqBYwGujdDvWZmXzN/PkycmAJ87Fh44YW0r3371PXRvz9suulXry5dCmtJf/JJasn//e/p1akT7LcfbLBB81/Tiiqkhd4bqI2IdwEk3U1ajzE/0APolHu/GvDPYhZpZgapW2TSpBTgNTXp69/+lgJcgq22gkGDoE8f2Hln+Pa3V/yzOnWCH/wgvUpFIYHeBZiWtz0d2K7eORcCf5H0C+DbwB4N/SBJA4ABABu05r/mzCxTixbBu+9+1ee95PXmm/DFF+mc1VZLYTtoUGqJ/9d/wVprZVt31op1U/QQ4JaIuErSDsBtkjaLiMX5J0XEMHIrkVdXV3sxUzP70r/+BXfdBffck1rdS4IboGvX1F0ycGAav73NNmlUSRYjSVqzQgJ9BtAtb7trbl++Y4C+ABExXlJHYG1gdjGKNLPy9Nlnafjf7bfDE0/A4sUpsH/5yxTgvXqlr506Nf6zrLBAnwD0lNSDFOT9gUPrnfM+0Ae4RdKmQEegrpiFmll5iICnn4YRI+DBB1Oob7ghnH02HHYYbLJJ1hWWrkYDPSIWShoIjCENSRwREZMkDQZqImIkcBrwR0mnkG6QHhkR7lIxsy/NmgW33ALDh381auTQQ1OI77yzu0+KQVnlbnV1dXiRaLPSFwHTp6cHb9q0Sa+2bdOrTZv0VOWIETByZHpwZ5dd4Nhj4aCDYOWVs66+9EiaGBENzgTjJ0XNbLnMnAkTJqRhg0tesxu5W1ZVBSefDMcc4y6V5uRAN7NGzZ4Nt96aukumTEn72rRJNy333jvdyNxoo9RaX7Qo3dxctCi9Vl0Vdt8dOnTI9hoqgQPdzBq0eDGMGwfDhqWRKAsWpL7u445Lj79vvXXTHtyx4nOgm9nXzJ0LN92Ugvydd2DNNdP472OPTS1ya70c6GYGwIcfwjXXwLXXplDfdVcYPDhNQtWxY9bVWSEc6GYVbuZM+N3v4Prr05jwAw+Ec84prTlMLHGgm1Wgzz+H8ePTgz3Dh6fJrQ45JD3c8/3vZ12drSgHulkFWBLgTz2VXi+9lEK8XTs44gg466y0iIOVNge6WRmbMwfOPferVnibNmliq0GDYLfdYKed0qyFVh4c6GZlKALuuANOOw0++CCNUOnXLw079ERX5cuBblZm3n4bTjwxjSHv3RsefzyNGbfy5+lwzMrEvHnw61/DFlvAq6/CDTek5dgc5pXDLXSzElZbm1rgjz+eWuTz5sHPfgZXXAHrrpt1ddbSHOhmJSQC/vrXNNzw8cfTMm2QRqgcdVQaerjTTtnWaNlxoJuViOefT+PEn302zaGy++5w6qnwox95yKElDnSzVu5vf0tDD0eNgs6dYejQNA3tt76VdWXW2hR0U1RSX0lTJNVKOquB41dLei33+j9JHxe/VLPKUlubVvTZaqvUOv/tb9O+E090mFvDGm2hS2oLDAX2BKYDEySNjIjJS86JiFPyzv8F4PvqZivoP/+Biy+Gyy6D9u1TN8sZZ8Aaa2RdmbV2hXS59AZqI+JdAEl3A/2AyUs5/xDgguKUZ1ZZnnkGBgxIi0gcdhhcfjmst17WVVmpKKTLpQswLW97em7fN0jaEOgB/HUpxwdIqpFUU1dXt7y1mpWtjz9OC0fsuit88UUawXLbbQ5zWz7FfrCoP3B/RCxq6GBEDIuI6oiorqqqKvJHm5WeiDQEsVcvuPnm9Kj+m2+mkStmy6uQQJ8BdMvb7prb15D+wF1NLcqsErz3Huy7b5p/fN114eWX4corvaybrbhCAn0C0FNSD0kdSKE9sv5JkjYB1gDGF7dEs/Iyfz5ccklqlY8bl57qfPnlNAuiWVM0elM0IhZKGgiMAdoCIyJikqTBQE1ELAn3/sDdERHNV65ZaRs3Lg07fPvt1DK/+mro1q3x7zMrREEPFkXEaGB0vX3n19u+sHhlmZWXGTPgzDPTlLYbbQSjR8Nee2VdlZUbz7Zo1ozefTeNXtloI7jvPjj//HTT02FuzcGP/ps1g0mT0pOdd92Vlnk7+mj41a+gR4+sK7Ny5kA3K6I33oALLoCHHkqjVU45JU2gtf76WVdmlcCBblYkd9+dprDt2BHOOy+t27nWWllXZZXEgW7WRIsXp1b5b36T1ux84AFYZ52sq7JK5EA3a4LPPoPDD09Pex59dFr2rUOHrKuySuVAN1tB77+fnvR84400nnzQIJCyrsoqmQPdbAW88ALsv3+a6nbUKOjbN+uKzDwO3Wy5zJ0LJ58MP/whdOoEL77oMLfWw4FuVoCI9JTnJpvAtdfCz3+e5l/ZdNOsKzP7irtczBoxaRKcdBI8/TRUV8PIkbDttllXZfZNbqGbLcWCBWn+la22gtdfhxtvTF0sDnNrrdxCN2tABBx/PIwYkYYjXnopeE0Wa+3cQjdrwEUXpTD/9a9h+HCHuZUGB7pZPTffnAL9yCNh8OCsqzErXEGBLqmvpCmSaiWdtZRzDpY0WdIkSXcWt0yzljFqVOpq+dGPYNgwPyhkpaXRPnRJbYGhwJ7AdGCCpJERMTnvnJ7A2cBOETFHkmeysJIzYQIcfDBsuSXcfz+0b591RWbLp5AWem+gNiLejYj5wN1Av3rn/BwYGhFzACJidnHLNGtetbWwzz5pUq1Ro2CVVbKuyGz5FRLoXYBpedvTc/vybQxsLOl5SS9KavDZOUkDJNVIqqmrq1uxis2KbNastILQ4sXw+OPQuXPWFZmtmGLdFG0H9AR2Aw4B/ihp9fonRcSwiKiOiOoqDxuwVuCtt2D77dOan3/+M3zve1lXZLbiCgn0GUD+uuRdc/vyTQdGRsSCiPgH8H+kgDdrtZ56CnbcEebNS0+B7rBD1hWZNU0hgT4B6Cmph6QOQH9gZL1zHia1zpG0NqkL5t0i1mlWVLfdBv/937DeevDSS37608pDo4EeEQuBgcAY4C3g3oiYJGmwpH1zp40BPpQ0GRgHnBERHzZX0WYrKgIuvDAtSrHLLmka3O7ds67KrDgUEZl8cHV1ddTU1GTy2VaZ5s+HY49NrfMjj4SbbvLqQlZ6JE2MiOqGjvlJUasIn34Ke++dwnzIkPRYv8Pcyo0n57KyV1eXhiW+9hrcemvqbjErRw50K2tTp6abn9OmwSOPpIeHzMqVA93K1qRJKcznzYMnnoCddsq6IrPm5T50K0svvJBGsQA8+6zD3CqDA93KzmOPwR57wNprw/PPw2abZV2RWctwoFtZmTwZDjooLeb83HMeY26VxYFuZeOzz1KYr7IKPPpomjnRrJL4pqiVhQg44QR4++10A3T99bOuyKzlOdCtLAwfnh4auugi6NMn62rMsuEuFyt5r70GAwfCnnvCuedmXY1ZdhzoVtI++QR++lNYay24/XZo2zbrisyy4y4XK1kRabKtf/wDxo3zTVAzB7qVrKFD4b774LLLvnqIyKySucvFStL48XDqqWlultNPz7oas9bBgW4lZ+bMNN68Wzf405+gjX+LzYACA11SX0lTJNVKOquB40dKqpP0Wu51bPFLNYMFC+Dgg2HOHHjwQVhzzawrMms9Gu1Dl9QWGArsSVoMeoKkkRExud6p90TEwGao0exLp52WJtu6807YcsusqzFrXQppofcGaiPi3YiYD9wN9Gvessy+6bbb4A9/gFNOgUMOyboas9ankEDvAkzL256e21ffgZJel3S/pG4N/SBJAyTVSKqpq6tbgXKtUr3yCgwYALvtBpdfnnU1Zq1TsW4n/RnoHhFbAE8AtzZ0UkQMi4jqiKiuqqoq0kdbufvgAzjggDQd7j33QDsPtjVrUCGBPgPIb3F3ze37UkR8GBFf5DZvBrYpTnlW6RYtSt0rM2emm6B+eMhs6QoJ9AlAT0k9JHUA+gMj80+QtF7e5r7AW8Ur0SrZkCHw5JNw/fWw7bZZV2PWujX6j9eIWChpIDAGaAuMiIhJkgYDNRExEvilpH2BhcBHwJHNWLNViHHjYPBgOOIIOProrKsxa/0UEZl8cHV1ddTU1GTy2db6zZ4NW20FnTpBTU1atMLMQNLEiKhu6JhvL1mrs3gxHH44fPQRPP64w9ysUA50a3WuvBLGjIEbboAttsi6GrPS4VkwrFUZPx7OOSfNcX7ccVlXY1ZaHOjWasyZA/37wwYbwB//CFLWFZmVFne5WKsQkUay/POf8PzzsNpqWVdkVnoc6NYqDBsGDz8MV10FvXtnXY1ZaXKXi2Xu/ffTIhV9+qSJt8xsxTjQLVMR6ebn4sXuNzdrKne5WKZuuy2NNb/mGujRI+tqzEqbW+iWmVmz4OSTYccdYaCXRjFrMge6ZWbgQJg3D4YP97qgZsXgLhfLxIMPwv33wyWXwCabZF2NWXlwu8ha3EcfwYknpsm3Tj8962rMyodb6NbiTj01rUL02GPQvn3W1ZiVD7fQrUWNGQO33gpnnglbb511NWblpaBAl9RX0hRJtZLOWsZ5B0oKSQ3O1WuVbf78dCP0e9+D887Luhqz8tNol4uktsBQYE9gOjBB0siImFzvvFWBQcBLzVGolb7rr4faWhg9Gjp2zLoas/JTSAu9N1AbEe9GxHzgbqBfA+cNAS4D/lPE+qxMfPRRWk5uzz2hb9+sqzErT4UEehdgWt729Ny+L0n6AdAtIkYt6wdJGiCpRlJNXV3dchdrpWvIEJg7N02+5cf7zZpHk2+KSmoD/A44rbFzI2JYRFRHRHVVVVVTP9pKxN//DtddB8ccA5tvnnU1ZuWrkECfAXTL2+6a27fEqsBmwFOS3gO2B0b6xqgtceaZqc988OCsKzErb4UE+gSgp6QekjoA/YGRSw5GxNyIWDsiukdEd+BFYN+IqGmWiq2kPP00PPQQnHUWdO6cdTVm5a3RQI+IhcBAYAzwFnBvREySNFjSvs1doJWuxYvTQ0TduqWvZta8CnpSNCJGA6Pr7Tt/Kefu1vSyrBzccQe88kqaInellbKuxqz8+UlRaxbz5sHZZ0N1NRx6aNbVmFUGz+VizeKqq2DGDLjrLk+Na9ZS/L+aFd0HH8Dll8P++8Muu2RdjVnlcKBb0V1+OXz2GfzmN1lXYlZZHOhWVDNnpoeIDj0UevXKuhqzyuJAt6K69NI0q+IFF2RdiVnlcaBb0UyfDjfeCIcfDj17Zl2NWeVxoFvRXHIJLFrkuc7NsuJAt6KYOhVuvjlNwNWjR9bVmFUmB7oVxZAhaVrcc8/NuhKzyuVAtyarrYVbboHjj0/ztphZNhzo1mSDB0OHDulRfzPLjgPdmuTtt9MkXCed5OlxzbLmQLcmufDCNJPir36VdSVm5kC3FTZhAtxzDwwaBF5R0Cx7DnRbIYsXw8CBqZvlzDOzrsbMoMBAl9RX0hRJtZLOauD48ZLekPSapOckeRaPMnfrrfDyy3DZZdCpU9bVmBmAImLZJ0htgf8D9gSmk9YYPSQiJued0ykiPsm93xc4MSL6LuvnVldXR02Nlx0tRXPnwsYbw0YbwfPPe75zs5YkaWJEVDd0rJAFLnoDtRHxbu6H3Q30A74M9CVhnvNtYNl/S1hJu+giqKuD0aMd5matSSGB3gWYlrc9Hdiu/kmSTgJOBToAuzf0gyQNAAYAbLDBBstbq7UCkyfDH/4Axx4L22yTdTVmlq9o7auIGBoR3wHOBH69lHOGRUR1RFRXeVhEyYmAX/4SVlkFLr4462rMrL5CWugzgPwHurvm9i3N3cANTSnKWqcHH4SxY1ML3X8fm7U+hbTQJwA9JfWQ1AHoD4zMP0FS/uzX+wB/L16J1hrMmwenngqbb57mbDGz1qfRFnpELJQ0EBgDtAVGRMQkSYOBmogYCQyUtAewAJgDHNGcRVvLu+wyeP99eOopaFfIv+vMrMU1OmyxuXjYYun4xz9g001hv/3g7ruzrsassi1r2KIHndkyRcAJJ0D79nDFFVlXY2bL4n882zLddReMGQPXXuu5zs1aO7fQbak+/BBOPhm22w5OPDHrasysMQ50W6rTT4c5c2DYMGjbNutqzKwxDnRr0NixaVm5M86ALbbIuhozK4QD3b7h88/huOPgu9+F887LuhozK5Rvito3DBkC77yTWukrrZR1NWZWKLfQ7Wtefz0NTzzqKNi9wSnWzKy1cqDblxYtgp//HNZYw2POzUqRu1zsS7//fVqF6M47Ya21sq7GzJaXW+gGpCA/++z0eH///llXY2YrwoFufPwx/L//B+uvDyNGgJR1RWa2ItzlUuEi4OijYfp0eO651H9uZqXJgV7hrrsOHnoIrrwyPeJvZqXLXS4VbOLE9Hj/j3+cFq8ws9JWUKBL6itpiqRaSWc1cPxUSZMlvS5prKQNi1+qFdPcuXDwwbDuuukRf/ebm5W+RgNdUltgKLAX0As4RFKveqe9ClRHxBbA/cDlxS7UiicijTefOjUtWOEhimbloZAWem+gNiLejYj5pEWg++WfEBHjImJebvNF0kLS1krdeCPcdx9cfDHsuGPW1ZhZsRQS6F2AaXnb03P7luYY4LGGDkgaIKlGUk1dXV3hVVrRvPQSDBoEe+2VZlI0s/JR1Juikg4DqoEGHxyPiGERUR0R1VVVVcX8aCvA7Nlw4IHQtSvcfju08S1xs7JSyLDFGUD+4mNdc/u+RtIewLnArhHxRXHKs2JZuDA9Afrhh/DCC7DmmllXZGbFVkgbbQLQU1IPSR2A/sDI/BMkbQ3cBOwbEbOLX6Y11TnnwLhxqf98662zrsbMmkOjgR4RC4GBwBjgLeDeiJgkabCkfXOnXQGsAtwn6TVJI5fy4ywD99+fZk884QQ44oisqzGz5qKIyOSDq6uro6amJpPPriRvvQW9e8Nmm8HTT0OHDllXZGZNIWliRFQ3dMy3xcrYJ5/A/vvDyiunYYoOc7Py5rlcytQXX8DPfga1tfDkk2lki5mVNwd6Gfroo9Qyf+YZ+MMfYLfdsq7IzFqCA73MvPMO7L03vPce3HEHHHpo1hWZWUtxoJeRF16Afv1g8eLUzbLLLllXZGYtyTdFy8S998Luu8Pqq8OLLzrMzSqRA73ERcCll6Yl5KqrYfx46Nkz66rMLAsO9BK2cCEcf3xa3PmQQ1I3y9prZ12VmWXFgV6i/v1v2G8/GDYsBfrtt0PHjllXZWZZ8k3REjRrFuyzD7z6KtxwQ2qlm5k50EvMlClpLvNZs+Dhh+EnP8m6IjNrLRzoJeT552HffaFdO3jqKdh226wrMrPWxH3oJWDxYrj+eujTJ930HD/eYW5m3+RAb+Xeew/23BNOOgl23TU9PLTRRllXZWatkQO9lYqAm26CzTeHCRPSaJbHH4e11sq6MjNrrdyH3gpNnQrHHpvGlffpA8OHw4YbZl2VmbV2BbXQJfWVNEVSraSzGjj+Q0mvSFoo6aDil1kZvvgCfv/71CofPz4NSXziCYe5mRWm0UCX1BYYCuwF9AIOkdSr3mnvA0cCdxa7wEqwaBHccgtsvDGccgpsvz288UYaXy5lXZ2ZlYpCWui9gdqIeDci5gN3A/3yT4iI9yLidWBxM9RYtiLgoYdgiy3gqKNgnXVSi/wvf4EePbKuzsxKTSGB3gWYlrc9PbdvuUkaIKlGUk1dXd2K/Iiy8eyzqSV+wAGphX7//fDyy7DHHllXZmalqkVHuUTEsIiojojqqqqqlvzoVmPOnHTD84c/hBkz4Oab4c034cAD3b1iZk1TyCiXGUC3vO2uuX22HCJSK/wXv4APPoAzzoALL0wLOJuZFUMhgT4B6CmpBynI+wNe2Gw5TJuWHgz6859h661h9Gj4wQ+yrsrMyk2jXS4RsRAYCIwB3gLujYhJkgZL2hdA0raSpgM/BW6SNKk5iy4Vn34KV18NvXqlMeVXXJH6yR3mZtYcCnqwKCJGA6Pr7Ts/7/0EUleMATU16cnOO++Ezz5Lj+7feKMf2Tez5uUnRYvk009TgA8bBq+8AiutBP37w3HHQe/evuFpZs3Pgd5E8+fDNdfAkCEp1DffHK67Dg47DFZbLevqzKySONCb4Mkn06iVt9+GH/8Yzj0XttvOrXEzy4ZnW1wB778PBx2U+sYXLIBHH00jWLbf3mFuZtlxC305zJ0LQ4fCxRenceVDhsDpp3txZjNrHRzojZg2DUaOhEceScu+LVgA+++fhiN6FkQza00c6PV8/jm8+mrqH3/kkTRiBdJMiCefnB7R3267bGs0M2tIRQf6okXphubLL8NLL6Wvr7+e9kupT/zSS6FfP9hkk6yrNTNbtooK9AiYMgXGjk0t8Keego8/TsdWWy0tvHzmmakFvv32aTpbM7NSUfaBPmcOjBqV5hgfOxb++c+0v0ePNFJll11SgPfsCW085sfMSlhZBvrMmfDww/DggzBuHCxcCFVVsPvuaY3OPn38GL6ZlZ+SDvTPPoNZs1KAz5wJ77yTbmS+8ELqXunZMw0rPOAA2GYbt8DNrLyVXKAPHw6//W0K8n//+5vHt9oKLroohXivXn7Qx8wqR8kF+jrrpMmu1l0XOnf++tcuXXwj08wqV8kF+k9+kl5mZvZ1BfUqS+oraYqkWklnNXD8W5LuyR1/SVL3YhdqZmbL1migS2oLDAX2AnoBh0jqVe+0Y4A5EfFd4GrgsmIXamZmy1ZIC703UBsR70bEfOBuoF+9c/oBt+be3w/0kXw70sysJRUS6F2AaXnb03P7GjwntwbpXGCt+j9I0gBJNZJq6urqVqxiMzNrUIuOzI6IYRFRHRHVVVVVLfnRZmZlr5BAnwF0y9vumtvX4DmS2gGrAR8Wo0AzMytMIYE+AegpqYekDkB/YGS9c0YCR+TeHwT8NSKieGWamVljGh2HHhELJQ0ExgBtgRERMUnSYKAmIkYCw4HbJNUCH5FC38zMWpCyakhLqgOmruC3rw18UMRySkWlXjdU7rX7uitLIde9YUQ0eBMys0BvCiW/5YMAAAM2SURBVEk1EVGddR0trVKvGyr32n3dlaWp1+35B83MyoQD3cysTJRqoA/LuoCMVOp1Q+Veu6+7sjTpukuyD93MzL6pVFvoZmZWjwPdzKxMlFygNzY3e7mQNELSbElv5u1bU9ITkv6e+7pGljU2B0ndJI2TNFnSJEmDcvvL+toldZT0sqS/5a77otz+Hrk1Bmpzaw50yLrW5iCpraRXJT2a2y7765b0nqQ3JL0mqSa3r0m/5yUV6AXOzV4ubgH61tt3FjA2InoCY3Pb5WYhcFpE9AK2B07K/Tcu92v/Atg9IrYEtgL6StqetLbA1bm1BuaQ1h4oR4OAt/K2K+W6/ysitsobe96k3/OSCnQKm5u9LETEM6RpFPLlzzt/K7BfixbVAiLiXxHxSu79p6T/ybtQ5tceyZJlz9vnXgHsTlpjAMrwugEkdQX2AW7ObYsKuO6laNLveakFeiFzs5ezdSPiX7n3M4F1syymueWWMtwaeIkKuPZct8NrwGzgCeAd4OPcGgNQvr/vvwd+BSzOba9FZVx3AH+RNFHSgNy+Jv2el9wi0ZZEREgq2zGnklYBHgBOjohP8hfAKtdrj4hFwFaSVgceAjbJuKRmJ+nHwOyImChpt6zraWE7R8QMSesAT0h6O//givyel1oLvZC52cvZLEnrAeS+zs64nmYhqT0pzO+IiAdzuyvi2gEi4mNgHLADsHpujQEoz9/3nYB9Jb1H6kLdHbiG8r9uImJG7uts0l/gvWni73mpBXohc7OXs/x5548AHsmwlmaR6z8dDrwVEb/LO1TW1y6pKtcyR9JKwJ6k+wfjSGsMQBled0ScHRFdI6I76f/nv0bE/1Dm1y3p25JWXfIe+G/gTZr4e15yT4pK2pvU57ZkbvaLMy6pWUi6C9iNNJ3mLOAC4GHgXmAD0tTDB0dE/RunJU3SzsCzwBt81ad6DqkfvWyvXdIWpJtgbUkNrXsjYrCkjUgt1zWBV4HDIuKL7CptPrkul9Mj4sflft2563sot9kOuDMiLpa0Fk34PS+5QDczs4aVWpeLmZkthQPdzKxMONDNzMqEA93MrEw40M3MyoQD3cysTDjQzczKxP8HoJx3q2FxRfUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QRG73l6qE-c",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18a29afe-c4fc-462f-a02f-983844a6e477"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_284aeae4-136a-417c-92b6-c84b150a39dd\", \"history.pkl\", 944)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See the Model in action\n",
        "\n",
        "After all  work it is finally time to see model generating text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90d11de-69d0-4a16-ceec-926cae73f999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope and gentle sport shall view ' 'will' ' be 'no show ' view ' 'will' thee worth thee my friend is to be give it so great friend shown cheeks of thy mind 'will' prove more worth or thee my part be give me loss to me thy state brood hate quite part live shown shown shown shown life with with heaven's distemper'd doth view ' grew arising weeds arising arising arising eye night and night night of night his part of love his part die worth thy 'will' love must be shown seen cross'd part still of love life\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Reference Course: [Natural Language Processing in TensorFlow](https://www.coursera.org/learn/natural-language-processing-tensorflow/home/welcome)"
      ],
      "metadata": {
        "id": "419Myxgpptr6"
      }
    }
  ],
  "metadata": {
    "dlai_version": "1.2.0",
    "accelerator": "GPU",
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Predicting the next word_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}